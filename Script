import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages
import seaborn as sns
import os
from scipy import stats

# Plot style
sns.set_theme(style="whitegrid")
plt.rcParams.update({"figure.autolayout": True})


class QualAnalyzerV20:
    def __init__(self, root):
        self.root = root
        self.root.title("Microcircuit Qual Analyzer V20 (Smart Limits + Inspector Slider Fix)")
        self.root.geometry("1600x950")

        # Data Storage
        self.data_dict = {}        # per sheet: wide data (SN + numeric cols)
        self.limits_dict = {}      # per sheet: {Parameter -> (LSL, USL)}
        self.param_map = {}        # base param -> [sheets]
        self.raw_previews = {}     # per sheet: raw DataFrame (no header)
        self.failures = []         # list of failure dicts
        self.current_file = None

        # Long-format tables
        self.measure_long = None   # DataFrame: Sheet, SN, Parameter, Value
        self.limit_long = None     # DataFrame: Sheet, Parameter, LSL, USL
        self.fail_long = None      # DataFrame: full failure table

        # Config Vars
        self.var_header_row = tk.IntVar(value=5)
        self.var_usl_row = tk.IntVar(value=12)
        self.var_lsl_row = tk.IntVar(value=13)
        self.var_data_start = tk.IntVar(value=18)
        self.var_data_end = tk.IntVar(value=0)
        self.var_sn_col = tk.IntVar(value=0)

        # Inspector sizing controls
        self.var_col_width = tk.IntVar(value=50)   # px
        self.var_row_height = tk.IntVar(value=22)   # px

        # Pagination
        self.page_size = 100
        self.current_page = 0
        self.total_rows = 0

        self.temps = ["Room", "Cold", "Hot"]
        self.is_tritemp = False

        # Matplotlib canvas references
        self.cpk_fig = None
        self.cpk_canvas = None
        self.trend_fig = None
        self.trend_canvas = None
        self.viz_fig = None
        self.viz_canvas = None

        # Distribution controls
        self.var_xmode = tk.StringVar(value="Sheet")
        self.var_show_limits = tk.StringVar(value="Off")

        # Treeview style for row height
        self.style = ttk.Style()
        self.style.configure("Inspector.Treeview", rowheight=self.var_row_height.get())
        self.style.configure("Treeview", rowheight=22)

        # --- Top controls ---
        control_frame = ttk.Frame(self.root, padding="10")
        control_frame.pack(fill=tk.X)

        btn_load = ttk.Button(control_frame, text="Load Data File (.xlsx)", command=self.load_file)
        btn_load.pack(side=tk.LEFT, padx=5)

        btn_reload = ttk.Button(control_frame, text="Reload Last File", command=self.reload_last_file)
        btn_reload.pack(side=tk.LEFT, padx=5)

        ttk.Label(control_frame, text="Page Size:").pack(side=tk.LEFT, padx=(20, 2))
        self.var_page_size = tk.IntVar(value=self.page_size)
        ttk.Entry(control_frame, textvariable=self.var_page_size, width=6).pack(side=tk.LEFT)

        ttk.Label(control_frame, text="Go to Page:").pack(side=tk.LEFT, padx=(20, 2))
        self.var_goto_page = tk.IntVar(value=1)
        ttk.Entry(control_frame, textvariable=self.var_goto_page, width=6).pack(side=tk.LEFT)
        ttk.Button(control_frame, text="Go", command=self.goto_page).pack(side=tk.LEFT, padx=2)

        self.lbl_status = ttk.Label(control_frame, text="Ready. Please load a file.")
        self.lbl_status.pack(side=tk.LEFT, padx=15)

        # Tabs
        self.tabs = ttk.Notebook(self.root)
        self.tabs.pack(expand=1, fill="both")

        self.tab_inspect = ttk.Frame(self.tabs)
        self.tab_cpk = ttk.Frame(self.tabs)
        self.tab_fail = ttk.Frame(self.tabs)
        self.tab_assess = ttk.Frame(self.tabs)
        self.tab_trend = ttk.Frame(self.tabs)
        self.tab_report = ttk.Frame(self.tabs)
        self.tab_visuals = ttk.Frame(self.tabs)

        self.tabs.add(self.tab_inspect, text="Data Inspector")
        self.tabs.add(self.tab_cpk, text="Cpk Health Check")
        self.tabs.add(self.tab_fail, text="Failure Analysis")
        self.tabs.add(self.tab_assess, text="Lot Assessment")
        self.tabs.add(self.tab_trend, text="Detailed Trend")
        self.tabs.add(self.tab_report, text="Report Generator")
        self.tabs.add(self.tab_visuals, text="Distributions")

        self._setup_inspect_tab()
        self._setup_cpk_tab()
        self._setup_fail_tab()
        self._setup_assess_tab()
        self._setup_trend_tab()
        self._setup_report_tab()
        self._setup_visuals_tab()

    # ----------------- Inspector tab -----------------
    def _setup_inspect_tab(self):
        frame = ttk.Frame(self.tab_inspect)
        frame.pack(fill=tk.BOTH, expand=True)

        config = ttk.LabelFrame(frame, text="Parsing Config", padding=10)
        config.pack(side=tk.LEFT, fill=tk.Y, padx=5, pady=5)

        def entry(lbl, var):
            f = ttk.Frame(config)
            f.pack(fill=tk.X, pady=2)
            ttk.Label(f, text=lbl, width=18).pack(side=tk.LEFT)
            ttk.Entry(f, textvariable=var, width=8).pack(side=tk.RIGHT)

        entry("Parameter (Row):", self.var_header_row)
        entry("Max Limit (Row):", self.var_usl_row)
        entry("Min Limit (Row):", self.var_lsl_row)
        entry("Data Start (Row):", self.var_data_start)
        entry("Data End (0=Auto):", self.var_data_end)
        entry("SN Column Idx:", self.var_sn_col)

        ttk.Button(config, text="Apply Changes", command=self.reparse_file).pack(fill=tk.X, pady=10)

        # Row-height slider only (column width slider is in top bar)
        size_box = ttk.LabelFrame(config, text="Inspector Size", padding=5)
        size_box.pack(fill=tk.X, pady=10)

        ttk.Label(size_box, text="Row Height").pack(anchor="w", pady=(0, 0))
        row_scale = ttk.Scale(
            size_box,
            from_=16,
            to=60,
            orient="horizontal",
            variable=self.var_row_height,
            command=lambda v: self._apply_inspector_row_height(),
        )
        row_scale.pack(fill=tk.X, pady=2)

        leg = ttk.LabelFrame(config, text="Legend", padding=5)
        leg.pack(fill=tk.X, pady=10)
        self._add_legend(leg, "Header Row", "#ffffcc")
        self._add_legend(leg, "Limits", "#ffcccc")
        self._add_legend(leg, "Data Start", "#ccffcc")
        self._add_legend(leg, "Data End", "#000000")

        right = ttk.Frame(frame)
        right.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)

        bar = ttk.Frame(right, padding=5)
        bar.pack(fill=tk.X)
        self.combo_inspect_sheet = ttk.Combobox(bar, state="readonly", width=20)
        self.combo_inspect_sheet.pack(side=tk.LEFT)
        self.combo_inspect_sheet.bind("<<ComboboxSelected>>", self.on_sheet_change)

        ttk.Button(bar, text="< Prev", command=self.prev_page).pack(side=tk.LEFT, padx=5)
        self.lbl_page = ttk.Label(bar, text="Page 1")
        self.lbl_page.pack(side=tk.LEFT)
        ttk.Button(bar, text="Next >", command=self.next_page).pack(side=tk.LEFT, padx=5)

        # Column width slider in top bar
        ttk.Label(bar, text="Col Width:").pack(side=tk.LEFT, padx=(15, 2))
        self.scale_col_width = tk.Scale(
            bar,
            from_=50,
            to=900,
            orient=tk.HORIZONTAL,
            showvalue=True,
            command=self.update_col_width
        )
        self.scale_col_width.set(self.var_col_width.get())
        self.scale_col_width.pack(side=tk.LEFT, padx=5)

        grid_f = ttk.Frame(right)
        grid_f.pack(fill=tk.BOTH, expand=True)

        self.tree_raw = ttk.Treeview(grid_f, show="headings", style="Inspector.Treeview")
        vsb = ttk.Scrollbar(grid_f, orient="vertical", command=self.tree_raw.yview)
        hsb = ttk.Scrollbar(grid_f, orient="horizontal", command=self.tree_raw.xview)
        self.tree_raw.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree_raw.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        vsb.pack(side=tk.RIGHT, fill=tk.Y)
        hsb.pack(side=tk.BOTTOM, fill=tk.X)

        self.tree_raw.tag_configure("HEADER", background="#ffffcc")
        self.tree_raw.tag_configure("USL", background="#ffcccc")
        self.tree_raw.tag_configure("LSL", background="#ccccff")
        self.tree_raw.tag_configure("DATA_START", background="#ccffcc")
        self.tree_raw.tag_configure("DATA_END", background="black", foreground="white")

    def _add_legend(self, parent, text, color):
        f = ttk.Frame(parent)
        f.pack(anchor="w")
        tk.Label(f, bg=color, width=2).pack(side=tk.LEFT)
        ttk.Label(f, text=text).pack(side=tk.LEFT, padx=5)

    def update_col_width(self, val):
        """Real-time update of inspector column widths from slider."""
        try:
            w = int(float(val))
        except ValueError:
            return
        self.var_col_width.set(w)
        # Critical: stretch=False prevents auto-shrinking when widget resizes
        for col in self.tree_raw["columns"]:
            self.tree_raw.column(col, width=w, stretch=False, anchor="w")
        self.tree_raw.update_idletasks()

    def _apply_inspector_row_height(self):
        rh = int(self.var_row_height.get())
        self.style.configure("Inspector.Treeview", rowheight=rh)
        self.tree_raw.update_idletasks()

    # ----------------- Other tabs setup -----------------
    def _setup_cpk_tab(self):
        frame = ttk.Frame(self.tab_cpk)
        frame.pack(fill=tk.BOTH, expand=True)

        # --- NEW: Control Bar for Interactivity ---
        ctrl_frame = ttk.Frame(frame, padding=5)
        ctrl_frame.pack(fill=tk.X)

        ttk.Label(ctrl_frame, text="Visualization Mode:").pack(side=tk.LEFT)

        self.var_cpk_viz_mode = tk.StringVar(value="Histogram (Distribution)")
        self.combo_cpk_mode = ttk.Combobox(ctrl_frame, textvariable=self.var_cpk_viz_mode, state="readonly", width=35)
        self.combo_cpk_mode['values'] = (
            "Histogram (Distribution)",
            "Box Plot (Compare Test Steps)",
            "Bubble Plot (Identify Outliers)",
            "Centering Analysis (Precision vs Accuracy)"
        )
        self.combo_cpk_mode.pack(side=tk.LEFT, padx=5)
        self.combo_cpk_mode.bind("<<ComboboxSelected>>", lambda e: self.plot_cpk_viz())
        # ------------------------------------------

        paned = ttk.PanedWindow(frame, orient=tk.HORIZONTAL)
        paned.pack(fill=tk.BOTH, expand=True)

        self.cpk_plot_frame = ttk.Frame(paned)
        paned.add(self.cpk_plot_frame, weight=3)

        tree_frame = ttk.Frame(paned)
        self.tree_cpk = ttk.Treeview(tree_frame, columns=("Param", "Cpk", "Mean"), show="headings")
        for c in ("Param", "Cpk", "Mean"):
            self.tree_cpk.heading(c, text=c, command=lambda col=c: self._sort_cpk_tree(col, False))
            self.tree_cpk.column(c, anchor="w", width=120)
        sb = ttk.Scrollbar(tree_frame, orient="vertical", command=self.tree_cpk.yview)
        self.tree_cpk.configure(yscrollcommand=sb.set)
        self.tree_cpk.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        sb.pack(side=tk.RIGHT, fill=tk.Y)
        paned.add(tree_frame, weight=1)

    def _setup_fail_tab(self):
        frame = ttk.Frame(self.tab_fail)
        frame.pack(fill=tk.BOTH, expand=True)
        top = ttk.Frame(frame)
        top.pack(fill=tk.X)
        self.lbl_fail_summary = ttk.Label(frame, text="Total Failures: 0", font=("Arial", 12, "bold"))
        self.lbl_fail_summary.pack(in_=top, side=tk.LEFT, pady=10, padx=5)
        ttk.Button(top, text="Export Failures to CSV", command=self.export_failures_csv).pack(side=tk.LEFT, padx=5)

        cols = ("Sheet", "SN", "Parameter", "Value", "LSL", "USL", "Type")
        self.tree_fail = ttk.Treeview(frame, columns=cols, show="headings")
        for c in cols:
            self.tree_fail.heading(c, text=c)
        vsb = ttk.Scrollbar(frame, orient="vertical", command=self.tree_fail.yview)
        self.tree_fail.configure(yscrollcommand=vsb.set)
        self.tree_fail.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        vsb.pack(side=tk.RIGHT, fill=tk.Y)

    def _setup_assess_tab(self):
        frame = ttk.Frame(self.tab_assess)
        frame.pack(fill=tk.BOTH, expand=True)

        top = ttk.Frame(frame)
        top.pack(fill=tk.X, pady=5)
        ttk.Button(top, text="Export Assessment to CSV", command=self.export_assessment_csv).pack(side=tk.LEFT, padx=5)

        self.txt_assess = tk.Text(frame, height=8, font=("Consolas", 11))
        self.txt_assess.pack(fill=tk.X, padx=10, pady=10)

        cols = ("Rank", "SN", "Deviation Score", "Max |Z|", "Count |Z|>3", "Count |Z|>6", "Failures")
        self.tree_rank = ttk.Treeview(frame, columns=cols, show="headings")
        for c in cols:
            self.tree_rank.heading(c, text=c)
        vsb = ttk.Scrollbar(frame, orient="vertical", command=self.tree_rank.yview)
        self.tree_rank.configure(yscrollcommand=vsb.set)
        self.tree_rank.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

    def _setup_trend_tab(self):
        frame = ttk.Frame(self.tab_trend)
        frame.pack(fill=tk.BOTH, expand=True)

        # --- Control Bar ---
        ctrl = ttk.Frame(frame, padding=5)
        ctrl.pack(fill=tk.X)

        # Parameter Selection
        ttk.Label(ctrl, text="Parameter:").pack(side=tk.LEFT)
        self.combo_trend_param = ttk.Combobox(ctrl, width=25, state="readonly")
        self.combo_trend_param.pack(side=tk.LEFT, padx=5)

        # [NEW] Auto-trigger plot when parameter changes
        self.combo_trend_param.bind("<<ComboboxSelected>>", lambda e: self.plot_detailed_trend())

        # Analysis Type Selection
        ttk.Label(ctrl, text="Analysis Type:").pack(side=tk.LEFT, padx=(15, 2))
        self.var_trend_type = tk.StringVar(value="Mean & Cpk Trend")
        self.combo_trend_type = ttk.Combobox(ctrl, textvariable=self.var_trend_type, state="readonly", width=30)
        self.combo_trend_type["values"] = (
            "Mean & Cpk Trend",
            "Box Plot Series (Spread)",
            "Spaghetti Plot (Individual Tracks)",
            "Drift / Delta Analysis (vs T0)"
        )
        self.combo_trend_type.pack(side=tk.LEFT, padx=5)
        self.combo_trend_type.current(0)

        # [NEW] Auto-trigger plot when graph type changes
        self.combo_trend_type.bind("<<ComboboxSelected>>", lambda e: self.plot_detailed_trend())

        # Keep the button as a backup
        ttk.Button(ctrl, text="Refresh Plot", command=self.plot_detailed_trend).pack(side=tk.LEFT, padx=15)

        self.trend_plot_frame = ttk.Frame(frame)
        self.trend_plot_frame.pack(fill=tk.BOTH, expand=True)

    def _setup_report_tab(self):
        frame = ttk.Frame(self.tab_report)
        frame.pack(fill=tk.BOTH, expand=True)
        ttk.Button(frame, text="Generate Screen Report", command=self.generate_screen_report).pack(pady=5)
        self.report_canvas = tk.Canvas(frame)
        sb = ttk.Scrollbar(frame, command=self.report_canvas.yview)
        self.report_frame = ttk.Frame(self.report_canvas)
        self.report_frame.bind(
            "<Configure>",
            lambda e: self.report_canvas.configure(scrollregion=self.report_canvas.bbox("all")),
        )
        self.report_canvas.create_window((0, 0), window=self.report_frame, anchor="nw")
        self.report_canvas.configure(yscrollcommand=sb.set)
        self.report_canvas.pack(side="left", fill="both", expand=True)
        sb.pack(side="right", fill="y")

    def _setup_visuals_tab(self):
        frame = ttk.Frame(self.tab_visuals)
        frame.pack(fill=tk.BOTH, expand=True)
        ctrl = ttk.Frame(frame)
        ctrl.pack(fill=tk.X)

        ttk.Label(ctrl, text="Param:").pack(side=tk.LEFT)
        self.combo_param_viz = ttk.Combobox(ctrl, width=30, state="readonly")
        self.combo_param_viz.pack(side=tk.LEFT, padx=5)

        ttk.Label(ctrl, text="X-Axis:").pack(side=tk.LEFT, padx=(15, 2))
        self.combo_xmode = ttk.Combobox(ctrl, width=8, state="readonly", textvariable=self.var_xmode)
        self.combo_xmode["values"] = ("Sheet", "SN")
        self.combo_xmode.current(0)
        self.combo_xmode.pack(side=tk.LEFT)

        ttk.Label(ctrl, text="Show Limits:").pack(side=tk.LEFT, padx=(15, 2))
        self.combo_limits = ttk.Combobox(ctrl, width=5, state="readonly", textvariable=self.var_show_limits)
        self.combo_limits["values"] = ("Off", "On")
        self.combo_limits.current(0)
        self.combo_limits.pack(side=tk.LEFT)

        ttk.Button(ctrl, text="Plot Distributions", command=self.plot_distribution).pack(side=tk.LEFT, padx=10)

        self.viz_frame = ttk.Frame(frame)
        self.viz_frame.pack(fill=tk.BOTH, expand=True)

    # ----------------- Structure detection -----------------
    def _detect_struct(self, df):
        col0 = df.iloc[:, 0].astype(str).str.strip()
        col0_lower = col0.str.lower()

        # Data start
        start = 18
        for i in range(len(col0_lower) - 1):
            if col0_lower.iloc[i] in ["1", "1.0"] and col0_lower.iloc[i + 1] in ["2", "2.0"]:
                start = i
                break
        self.var_data_start.set(start)

        # Data end
        end = len(df) - 1
        for i in range(start, len(col0_lower)):
            if col0_lower.iloc[i] in ["nan", "none", ""]:
                end = i - 1
                break
        self.var_data_end.set(end)

        search_top = max(0, start - 25)
        search_slice = col0_lower.iloc[search_top:start]

        def find_best_row(patterns_include, patterns_exclude=()):
            mask = search_slice.apply(
                lambda s: any(p in s for p in patterns_include) and not any(e in s for e in patterns_exclude)
            )
            idx = np.where(mask.to_numpy())[0]
            if len(idx):
                return search_top + int(idx[-1])
            return None

        max_row = find_best_row(
            ["max limit", "upper limit", "usl"],
            ["max reading", "maximum reading"],
        )
        min_row = find_best_row(
            ["min limit", "lower limit", "lsl"],
            ["min reading", "minimum reading"],
        )

        if max_row is None or min_row is None:
            u, l = 12, 13
            for i in range(search_top, start):
                t = col0_lower.iloc[i]
                if "max" in t and "reading" not in t:
                    u = i
                elif "min" in t and "reading" not in t:
                    l = i
            if max_row is None:
                max_row = u
            if min_row is None:
                min_row = l

        self.var_usl_row.set(max_row)
        self.var_lsl_row.set(min_row)
        header_row = max(min(max_row, min_row) - 1, 0)
        self.var_header_row.set(header_row)

    # ----------------- File loading / parsing -----------------
    def load_file(self):
        f = filedialog.askopenfilename(filetypes=[("Excel Files", "*.xlsx *.xls")])
        if not f:
            return
        self.current_file = f
        self._load_from_path(f)

    def reload_last_file(self):
        if not self.current_file or not os.path.isfile(self.current_file):
            messagebox.showinfo("Info", "No previous file found.")
            return
        self._load_from_path(self.current_file)

    def _load_from_path(self, path):
        self.lbl_status.config(text=f"Loading: {os.path.basename(path)}")
        self.root.update()
        try:
            xls = pd.ExcelFile(path)
            self.raw_previews = {
                s: pd.read_excel(xls, sheet_name=s, header=None, engine="openpyxl")
                for s in xls.sheet_names
            }
            if not xls.sheet_names:
                raise ValueError("Workbook has no sheets.")

            df0 = self.raw_previews[xls.sheet_names[0]]
            self._detect_struct(df0)

            self.combo_inspect_sheet["values"] = xls.sheet_names
            if xls.sheet_names:
                self.combo_inspect_sheet.current(0)

            self.reparse_file()
        except Exception as e:
            messagebox.showerror("Error", str(e))
            self.lbl_status.config(text="Error during load.")

    def reparse_file(self):
        if not self.current_file:
            return
        self.page_size = max(10, self.var_page_size.get() or 100)

        h, u, l = self.var_header_row.get(), self.var_usl_row.get(), self.var_lsl_row.get()
        d_s, d_e = self.var_data_start.get(), self.var_data_end.get()
        sn_idx = self.var_sn_col.get()

        self.data_dict.clear()
        self.limits_dict.clear()
        self.param_map.clear()
        self.failures.clear()
        self.measure_long = []
        self.limit_long = []

        try:
            for sheet, raw in self.raw_previews.items():
                if h >= len(raw):
                    continue

                raw_header = raw.iloc[h].values
                clean_header = self._process_headers(raw_header)

                usls = pd.to_numeric(raw.iloc[u].values, errors="coerce") if u < len(raw) else []
                lsls = pd.to_numeric(raw.iloc[l].values, errors="coerce") if l < len(raw) else []

                e = d_e if d_e > d_s else len(raw) - 1
                e = min(e, len(raw) - 1)
                df = raw.iloc[d_s : e + 1, :].copy()

                valid = min(len(clean_header), df.shape[1])
                df = df.iloc[:, :valid]

                col_names = list(clean_header[:valid])
                if sn_idx < len(col_names):
                    col_names[sn_idx] = "SN"
                df.columns = col_names

                df = df.dropna(subset=["SN"], how="all")
                df["SN"] = df["SN"].astype(str)

                for c in df.columns:
                    if c != "SN":
                        df[c] = pd.to_numeric(df[c], errors="coerce")

                self.data_dict[sheet] = df

                s_lims = {}
                for i, p in enumerate(clean_header[:valid]):
                    if i == sn_idx:
                        continue
                    if p not in df.columns:
                        continue

                    base = self._get_base(p)
                    if base not in self.param_map:
                        self.param_map[base] = []
                    if sheet not in self.param_map[base]:
                        self.param_map[base].append(sheet)

                    uv = usls[i] if i < len(usls) else np.nan
                    lv = lsls[i] if i < len(lsls) else np.nan
                    s_lims[p] = (lv, uv)

                    self.limit_long.append(
                        {"Sheet": sheet, "Parameter": p, "LSL": lv, "USL": uv}
                    )

                self.limits_dict[sheet] = s_lims

                value_cols = [c for c in df.columns if c != "SN"]
                melted = df.melt(id_vars=["SN"], value_vars=value_cols, var_name="Parameter", value_name="Value")
                melted["Sheet"] = sheet
                self.measure_long.append(melted)

            if not self.measure_long:
                self.lbl_status.config(text="No data parsed.")
                return

            self.measure_long = pd.concat(self.measure_long, ignore_index=True)
            self.limit_long = pd.DataFrame(self.limit_long).drop_duplicates()

            merged = pd.merge(
                self.measure_long,
                self.limit_long,
                on=["Sheet", "Parameter"],
                how="left",
            )

            merged["FailHigh"] = (~merged["USL"].isna()) & (merged["Value"] > merged["USL"])
            merged["FailLow"]  = (~merged["LSL"].isna()) & (merged["Value"] < merged["LSL"])
            merged["FailType"] = np.where(
                merged["FailHigh"], "High",
                np.where(merged["FailLow"], "Low", "")
            )

            self.fail_long = merged[(merged["FailHigh"] | merged["FailLow"]) & (~merged["Value"].isna())]

            self.failures = []
            for _, r in self.fail_long.iterrows():
                self.failures.append(
                    {
                        "Sheet": r["Sheet"],
                        "SN": r["SN"],
                        "Parameter": r["Parameter"],
                        "Value": r["Value"],
                        "LSL": r["LSL"],
                        "USL": r["USL"],
                        "Type": r["FailType"],
                    }
                )

            self.combo_trend_param["values"] = sorted(list(self.param_map.keys()))
            self.combo_param_viz["values"] = self.combo_trend_param["values"]

            self.current_page = 0
            self.update_inspector_grid(None)
            self.plot_cpk_viz()
            self.populate_failures()
            self.calculate_assessment()
            self.lbl_status.config(text="Analysis Complete.")

        except Exception as e:
            messagebox.showerror("Error", str(e))
            self.lbl_status.config(text="Error during parse.")

    # ----------------- Inspector pagination -----------------
    def update_inspector_grid(self, _event):
        sheet = self.combo_inspect_sheet.get()
        if sheet not in self.raw_previews:
            return
        df = self.raw_previews[sheet]
        self.total_rows = len(df)
        self.lbl_page.config(text=f"Page {self.current_page + 1}")
        self.page_size = max(10, self.var_page_size.get() or 100)

        self.tree_raw.delete(*self.tree_raw.get_children())
        self.tree_raw["columns"] = list(range(len(df.columns)))

        start = self.current_page * self.page_size
        subset = df.iloc[start : start + self.page_size]

        w = int(self.var_col_width.get())

        for i in range(len(df.columns)):
            self.tree_raw.heading(i, text=str(i))
            # stretch=False ensures manual width is honored
            self.tree_raw.column(i, width=w, stretch=False, anchor="w")

        h = self.var_header_row.get()
        u, l = self.var_usl_row.get(), self.var_lsl_row.get()
        ds, de = self.var_data_start.get(), self.var_data_end.get()

        for i, row in subset.iterrows():
            vals = [str(x) if not pd.isna(x) else "" for x in row]
            tag = ""
            if i == h:
                tag = "HEADER"
            elif i == u:
                tag = "USL"
            elif i == l:
                tag = "LSL"
            elif i == ds:
                tag = "DATA_START"
            elif de > 0 and i == de:
                tag = "DATA_END"
            self.tree_raw.insert("", "end", values=vals, tags=(tag,))

        self._apply_inspector_row_height()
        self.tree_raw.update_idletasks()

    def prev_page(self):
        if self.current_page > 0:
            self.current_page -= 1
            self.update_inspector_grid(None)

    def next_page(self):
        sheet = self.combo_inspect_sheet.get()
        if sheet in self.raw_previews:
            total = len(self.raw_previews[sheet])
            max_page = max(0, (total - 1) // self.page_size)
            if self.current_page < max_page:
                self.current_page += 1
                self.update_inspector_grid(None)

    def goto_page(self):
        sheet = self.combo_inspect_sheet.get()
        if sheet not in self.raw_previews:
            return
        total = len(self.raw_previews[sheet])
        max_page = max(0, (total - 1) // self.page_size)
        p = max(0, min(max_page, self.var_goto_page.get() - 1))
        self.current_page = p
        self.update_inspector_grid(None)

    def on_sheet_change(self, _event):
        self.current_page = 0
        self.update_inspector_grid(None)

    # ----------------- Cpk plotting -----------------
    def plot_cpk_viz(self):
        # 1. Gather Data
        data = []
        for s, df in self.data_dict.items():
            for c in df.columns:
                if c == "SN": continue
                v = df[c].dropna()
                l, u = self.limits_dict[s].get(c, (np.nan, np.nan))
                cpk = self._calc_robust_cpk(v, l, u)

                if not pd.isna(cpk):
                    # Calculate "Centering" (0.0 = LSL, 1.0 = USL, 0.5 = Perfect Center)
                    centering = np.nan
                    if not pd.isna(l) and not pd.isna(u) and (u != l):
                        mean_val = v.mean()
                        centering = (mean_val - l) / (u - l)

                    data.append({
                        "Sheet": s,
                        "Param": c,
                        "Cpk": cpk,
                        "Mean": v.mean(),
                        "Centering": centering
                    })

        if not data: return
        df_p = pd.DataFrame(data)
        df_p = df_p.replace([np.inf, -np.inf], np.nan).dropna(subset=["Cpk"])
        if df_p.empty: return

        # 2. Update Treeview (Standard for all views)
        self.tree_cpk.delete(*self.tree_cpk.get_children())
        for _, r in df_p.sort_values("Cpk").iterrows():
            lbl = f"{r['Sheet']}:{r['Param']}"
            self.tree_cpk.insert("", "end", values=(lbl, f"{r['Cpk']:.3f}", f"{r['Mean']:.3f}"))

        # 3. Handle Canvas
        if self.cpk_canvas is None:
            self.cpk_fig = plt.Figure(figsize=(12, 6), dpi=100)  # Use Figure, not subplots, for easier clearing
            self.cpk_canvas = FigureCanvasTkAgg(self.cpk_fig, master=self.cpk_plot_frame)
            self.cpk_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        else:
            self.cpk_fig.clf()

        # 4. Dispatch Plot Type
        mode = self.var_cpk_viz_mode.get()
        ax = self.cpk_fig.add_subplot(111)

        # --- MODE A: Histogram (Classic) ---
        if "Histogram" in mode:
            viz_max = 4.0
            clipped = df_p["Cpk"].clip(upper=viz_max)
            ax.hist(clipped, bins=25, range=(0, viz_max), color="#4C72B0", edgecolor="white")
            ax.axvline(1.33, color="orange", ls="--", label="1.33 Limit")
            ax.axvline(1.67, color="green", ls="--", label="1.67 Limit")
            ax.set_title("Overall Cpk Distribution", fontsize=12, fontweight='bold')
            ax.set_xlabel(f"Cpk (Capped at {viz_max})")
            ax.legend()

        # --- MODE B: Box Plot (Compare Test Steps) ---
        elif "Box Plot" in mode:
            # FIX 1: Clip extreme values at 10.0 instead of letting the plot cut them off.
            # Cpk > 10 is statistically "Infinity" for a Qual.
            # This ensures even "perfect" parameters are visible at the top of the chart.
            plot_data = df_p.copy()
            plot_data["Cpk"] = plot_data["Cpk"].clip(upper=10.0)

            # Create the box plot using this "safe" data
            sns.boxplot(data=plot_data, x="Sheet", y="Cpk", ax=ax, palette="vlag")
            sns.stripplot(data=plot_data, x="Sheet", y="Cpk", ax=ax, color="black", alpha=0.3, jitter=True, size=3)

            # Add the limit line
            ax.axhline(1.33, color="red", ls="--", alpha=0.5, label="1.33 Limit")

            # FIX 2: Remove the hard "5" limit.
            # Instead, set the top to slightly above the highest value in the data (max 10).
            # This "Auto-fits" the chart to your actual data height.
            current_max = plot_data["Cpk"].max()
            ax.set_ylim(0, current_max * 1.1)

            ax.set_title("Process Capability by Electrical Test Step", fontsize=12, fontweight='bold')
            ax.set_xlabel("Test Step / Sheet")

        # --- MODE C: Bubble Plot (Outlier Spotter) ---
        elif "Bubble" in mode:
            # X = Sheet (Categorical mapped to Int), Y = Cpk
            sheets = sorted(df_p["Sheet"].unique())
            sheet_map = {name: i for i, name in enumerate(sheets)}
            df_p["SheetIdx"] = df_p["Sheet"].map(sheet_map)

            # Size: Inverse of Cpk (Smaller Cpk = Bigger Risk Bubble)
            # We clip the denominator so Cpk=0 doesn't cause div/0 or infinite size
            # We also cap the Cpk used for sizing at 3.0, so "Good" points (Cpk>3) represent minimum risk size
            size_cpk = df_p["Cpk"].clip(lower=0.1, upper=3.0)
            sizes = (1.0 / size_cpk) * 250

            # Color map: Red (Bad) to Green (Good)
            # We clip color data at 2.0 so super-high Cpk doesn't skew the color scale
            color_data = df_p["Cpk"].clip(upper=2.0)

            sc = ax.scatter(
                df_p["SheetIdx"],
                df_p["Cpk"],
                s=sizes,
                c=color_data,
                cmap="RdYlGn",
                alpha=0.6,
                edgecolors="black",
                linewidth=0.5
            )

            # --- THE FIX: SYMLOG SCALE ---
            # 'linthresh=3' means: Be Linear from 0 to 3. Be Logarithmic above 3.
            # This keeps your 0-2 range perfectly readable while shrinking the 10,000 outlier.
            ax.set_yscale('symlog', linthresh=3)

            # Force specific y-ticks so the linear part is readable
            # We want to see 0, 1, 1.33, 2, 3 clearly.
            # Then powers of 10 for the outliers.
            from matplotlib.ticker import FixedLocator, ScalarFormatter

            # Combine standard linear ticks with log ticks
            major_ticks = [0, 1, 1.33, 2, 3, 10, 100, 1000, 10000]
            # Filter ticks to only those within actual data range (plus a buffer)
            max_val = df_p["Cpk"].max()
            visible_ticks = [t for t in major_ticks if t <= max_val * 10]

            ax.yaxis.set_major_locator(FixedLocator(visible_ticks))
            ax.yaxis.set_major_formatter(ScalarFormatter())  # Formatting numbers as 10, 100 (not 10^2)

            ax.set_xticks(range(len(sheets)))
            ax.set_xticklabels(sheets, rotation=45, ha="right")
            ax.set_title("Cpk Outlier Detection (Symlog Scale)", fontsize=12, fontweight='bold')
            ax.set_ylabel("Cpk Value (Linear ≤ 3, Log > 3)")

            # Add grid for both major (labeled) and minor ticks
            ax.grid(True, which='major', linestyle="-", alpha=0.5)
            ax.grid(True, which='minor', linestyle=":", alpha=0.2)

            # Add colorbar
            plt.colorbar(sc, ax=ax, label="Cpk (Color capped at 2.0)")

        # --- MODE D: Centering Analysis (The Engineer's Favorite) ---
        elif "Centering" in mode:
            # Filter for items that actually have limits (Centering != NaN)
            valid = df_p.dropna(subset=["Centering"])
            if valid.empty:
                ax.text(0.5, 0.5, "No parameters with both LSL & USL found", ha='center')
            else:
                sc = ax.scatter(
                    valid["Centering"],
                    valid["Cpk"],
                    c=valid["Cpk"],
                    cmap="RdYlGn",
                    edgecolors="grey",
                    alpha=0.7
                )

                # Draw "Goal Posts"
                ax.axvline(0.0, color="red", ls="-", label="LSL")
                ax.axvline(1.0, color="red", ls="-", label="USL")
                ax.axvline(0.5, color="grey", ls=":", label="Target")

                ax.set_xlim(-0.2, 1.2)
                ax.set_ylim(0, 4)
                ax.set_title("Centering Analysis: Are failures due to Noise or Drift?", fontsize=12, fontweight='bold')
                ax.set_xlabel("Mean Position (0=LSL, 0.5=Center, 1=USL)")
                ax.set_ylabel("Cpk (Precision)")
                ax.legend(loc='upper right')

        self.cpk_fig.tight_layout()
        self.cpk_canvas.draw()

    # ----------------- Detailed Trend (no 3σ shading) -----------------
    def plot_detailed_trend(self):
        try:
            param = self.combo_trend_param.get()
            plot_type = self.var_trend_type.get()

            # 1. Clear previous plot immediately to prevent "stale" data confusion
            if self.trend_canvas is None:
                self.trend_fig = plt.Figure(figsize=(10, 6), dpi=100)
                self.trend_canvas = FigureCanvasTkAgg(self.trend_fig, master=self.trend_plot_frame)
                self.trend_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            else:
                self.trend_fig.clf()

            # Force a draw now so if we return early, the user sees a blank screen (not the old plot)
            self.trend_canvas.draw()

            if not param or self.measure_long is None:
                return

            # 2. Global Definition of sheet_order (CRITICAL FIX)
            # This must exist before any if/else blocks try to use it
            sheet_order = list(self.data_dict.keys())

            # 3. Create the Base Subset (for Box/Spaghetti plots)
            # We filter by the base parameter name to capture all temps
            subset = self.measure_long[
                self.measure_long["Parameter"].apply(lambda x: self._get_base(x) == param)].copy()

            if subset.empty:
                # If no data found, just exit (screen is already cleared)
                return

            # Sort subset by Sheet order
            subset["Sheet"] = subset["Sheet"].astype(str)
            subset["Sheet"] = pd.Categorical(subset["Sheet"], categories=sheet_order, ordered=True)
            subset = subset.sort_values("Sheet")

            ax = self.trend_fig.add_subplot(111)

            # =========================================================
            # MODE 1: Mean & Cpk Trend (Tri-Temp Robust)
            # =========================================================
            if "Mean & Cpk" in plot_type:
                ax2 = ax.twinx()
                styles = {
                    "Room": ("green", "o", "-"),
                    "Cold": ("blue", "D", "--"),
                    "Hot": ("red", "s", ":"),
                    "Data": ("black", "x", "-.")
                }

                def get_temp(p_name):
                    if "(Room)" in p_name: return "Room"
                    if "(Cold)" in p_name: return "Cold"
                    if "(Hot)" in p_name: return "Hot"
                    return "Data"

                # Find specific columns (e.g., Icc Room, Icc Hot)
                all_params = self.measure_long["Parameter"].unique()
                relevant_cols = [p for p in all_params if self._get_base(p) == param]

                # Gather data by temp
                temp_groups = {}
                for col in relevant_cols:
                    temp = get_temp(col)
                    if temp not in temp_groups:
                        temp_groups[temp] = {"sheets": [], "means": [], "cpks": []}

                    for s in sheet_order:
                        temp_groups[temp]["sheets"].append(s)
                        df = self.data_dict[s]
                        if col in df.columns:
                            v = df[col].dropna()
                            if not v.empty:
                                temp_groups[temp]["means"].append(v.mean())
                                l, u = self.limits_dict[s].get(col, (np.nan, np.nan))
                                cpk = self._calc_robust_cpk(v, l, u)
                                temp_groups[temp]["cpks"].append(cpk)
                            else:
                                temp_groups[temp]["means"].append(np.nan)
                                temp_groups[temp]["cpks"].append(np.nan)
                        else:
                            temp_groups[temp]["means"].append(np.nan)
                            temp_groups[temp]["cpks"].append(np.nan)

                # Plot
                lines, labels = [], []
                for temp, data in temp_groups.items():
                    # Skip if no data
                    if all(pd.isna(x) for x in data["means"]): continue

                    c, mk, ls = styles.get(temp, styles["Data"])
                    l1 = ax.plot(data["sheets"], data["means"], color=c, marker=mk, ls="-", alpha=0.8,
                                 label=f"{temp} Mean")
                    l2 = ax2.plot(data["sheets"], data["cpks"], color=c, marker=mk, ls=ls, lw=1.5, alpha=0.5,
                                  label=f"{temp} Cpk")
                    lines.extend(l1 + l2)
                    labels.extend([l1[0].get_label(), l2[0].get_label()])

                ax.set_title(f"Tri-Temp Trend: {param}")
                ax.set_ylabel("Mean Value")
                ax2.set_ylabel("Cpk (Dashed)")
                ax2.axhline(1.33, color="gray", ls="--", alpha=0.5)
                if lines:
                    ax.legend(lines, labels, loc='upper left', fontsize=8, ncol=2)
                ax.grid(True, alpha=0.3)

            # =========================================================
            # MODE 2: Box Plot (Spread)
            # =========================================================
            elif "Box Plot" in plot_type:
                sns.boxplot(data=subset, x="Sheet", y="Value", hue="Sheet", legend=False, ax=ax, palette="Blues",
                            showfliers=False)
                sns.stripplot(data=subset, x="Sheet", y="Value", ax=ax, color="black", alpha=0.3, size=2, jitter=True)
                ax.set_title(f"Distribution Trend: {param}")
                ax.set_xlabel("Readpoint")
                ax.grid(True, axis='y', alpha=0.5)

            # =========================================================
            # MODE 3: Spaghetti Plot (Maverick Detection)
            # =========================================================
            elif "Spaghetti" in plot_type:
                unique_sn = subset["SN"].nunique()
                alpha_val = 0.5 if unique_sn < 50 else 0.1
                sns.lineplot(data=subset, x="Sheet", y="Value", hue="SN", estimator=None, units="SN", ax=ax,
                             palette="dark:grey", legend=False, alpha=alpha_val, lw=1)

                # Highlight Mean
                sns.lineplot(data=subset, x="Sheet", y="Value", ax=ax, color="red", lw=3, errorbar=None, label="Mean")
                ax.set_title(f"Individual Unit Trajectories (N={unique_sn})")
                ax.set_xlabel("Readpoint")
                ax.legend(loc='upper right')

            # =========================================================
            # MODE 4: Drift Analysis (Robust)
            # =========================================================
            elif "Drift" in plot_type:
                # Identify correct columns (Room/Cold/Hot) for this param
                all_params = self.measure_long["Parameter"].unique()
                relevant_cols = [p for p in all_params if self._get_base(p) == param]
                drift_subset = self.measure_long[self.measure_long["Parameter"].isin(relevant_cols)].copy()

                if drift_subset.empty: return

                drift_subset["Sheet"] = drift_subset["Sheet"].astype(str)
                pivoted = drift_subset.pivot_table(index="SN", columns="Sheet", values="Value", aggfunc='first')

                valid_sheets = [s for s in sheet_order if s in pivoted.columns]
                if len(valid_sheets) < 2:
                    ax.text(0.5, 0.5, "Insufficient timepoints for drift analysis", ha='center')
                else:
                    pivoted = pivoted[valid_sheets]
                    inc_drift = pivoted.diff(axis=1)
                    t0 = pivoted.iloc[:, 0]
                    cum_drift = pivoted.subtract(t0, axis=0)
                    cum_mean = cum_drift.mean(axis=0)

                    melted = inc_drift.reset_index().melt(id_vars="SN", var_name="Sheet", value_name="Drift")

                    ax2 = ax.twinx()
                    ax.axhline(0, color='black', alpha=0.3)
                    sns.boxplot(data=melted, x="Sheet", y="Drift", hue="Sheet", legend=False, ax=ax, palette="coolwarm",
                                showfliers=False, boxprops=dict(alpha=0.6))

                    ax2.plot(range(len(valid_sheets)), cum_mean.values, color="purple", marker="D", ls="--", lw=2,
                             label="Cumulative Mean Drift")

                    ax.set_title(f"Step-by-Step vs Cumulative Drift: {param}")
                    ax.set_ylabel("Incremental Drift (Step N - N-1)")
                    ax2.set_ylabel("Total Mean Drift (vs T0)", color="purple")
                    ax2.tick_params(axis='y', labelcolor="purple")
                    ax2.legend(loc='upper left')
                    ax.grid(True, alpha=0.3)

            self.trend_fig.tight_layout()
            self.trend_canvas.draw()

        except Exception as e:
            # Catch crashes (like NameError or ValueError) and show them
            messagebox.showerror("Plot Error", f"An error occurred while plotting:\n{str(e)}")
            # Clear the canvas so the user knows it failed
            if self.trend_fig:
                self.trend_fig.clf()
                self.trend_canvas.draw()

    # ----------------- Distributions tab -----------------
    def plot_distribution(self):
        param = self.combo_param_viz.get()
        if not param or self.measure_long is None:
            return

        xmode = self.var_xmode.get()
        show_limits = self.var_show_limits.get() == "On"

        base_param = param
        sub = self.measure_long[self.measure_long["Parameter"].apply(lambda p: self._get_base(p) == base_param)]
        if sub.empty:
            messagebox.showinfo("Info", f"No numeric data found for {param}")
            return

        limits_sub = self.limit_long[self.limit_long["Parameter"].isin(sub["Parameter"].unique())]
        dist_df = pd.merge(sub, limits_sub, on=["Sheet", "Parameter"], how="left")

        if self.viz_canvas is None:
            self.viz_fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            self.viz_canvas = FigureCanvasTkAgg(self.viz_fig, master=self.viz_frame)
            self.viz_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        else:
            self.viz_fig.clf()
            ax1, ax2 = self.viz_fig.subplots(1, 2)

        def temp_of(p):
            for t in ["Room", "Cold", "Hot"]:
                if f"({t})" in p:
                    return t
            return "Data"

        dist_df["Temp"] = dist_df["Parameter"].apply(temp_of)

        if self.is_tritemp:
            sns.histplot(
                data=dist_df,
                x="Value",
                hue="Temp",
                kde=True,
                ax=ax1,
                palette={"Room": "green", "Cold": "blue", "Hot": "red"},
                multiple="layer",
                alpha=0.5,
            )
            ax1.set_title(f"{base_param} Distribution by Temperature")
        else:
            sns.histplot(dist_df["Value"], kde=True, ax=ax1, color="steelblue", edgecolor="black")
            ax1.set_title(f"{base_param} Overall Distribution")

        if show_limits:
            if self.is_tritemp:
                for t, c in [("Room", "green"), ("Cold", "blue"), ("Hot", "red")]:
                    tmp = dist_df[dist_df["Temp"] == t]
                    if not tmp.empty:
                        l_vals = tmp["LSL"].dropna().unique()
                        u_vals = tmp["USL"].dropna().unique()
                        if l_vals.size:
                            ax1.axvline(l_vals[0], color=c, linestyle="--", alpha=0.7)
                        if u_vals.size:
                            ax1.axvline(u_vals[0], color=c, linestyle="--", alpha=0.7)
            else:
                l_vals = dist_df["LSL"].dropna().unique()
                u_vals = dist_df["USL"].dropna().unique()
                if l_vals.size:
                    ax1.axvline(l_vals[0], color="black", linestyle="--", alpha=0.7)
                if u_vals.size:
                    ax1.axvline(u_vals[0], color="black", linestyle="--", alpha=0.7)

        if xmode == "Sheet":
            x_col = "Sheet"
            ax2.set_title(f"{base_param} by Sheet / Lot")
        else:
            x_col = "SN"
            ax2.set_title(f"{base_param} by Serial Number")

        dist_plot = dist_df.copy()
        if xmode == "SN":
            counts = dist_plot["SN"].value_counts().head(50).index
            dist_plot = dist_plot[dist_plot["SN"].isin(counts)]

        if self.is_tritemp:
            sns.boxplot(
                data=dist_plot,
                x=x_col,
                y="Value",
                hue="Temp",
                ax=ax2,
                palette={"Room": "green", "Cold": "blue", "Hot": "red"},
            )
            ax2.legend(title="Temp", fontsize=8)
        else:
            sns.boxplot(data=dist_plot, x=x_col, y="Value", ax=ax2, color="lightgray")

        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha="right")

        if show_limits:
            if self.is_tritemp:
                for t, c in [("Room", "green"), ("Cold", "blue"), ("Hot", "red")]:
                    tmp = dist_plot[dist_plot["Temp"] == t]
                    if not tmp.empty:
                        l_vals = tmp["LSL"].dropna().unique()
                        u_vals = tmp["USL"].dropna().unique()
                        if l_vals.size:
                            ax2.axhline(l_vals[0], color=c, linestyle="--", alpha=0.7)
                        if u_vals.size:
                            ax2.axhline(u_vals[0], color=c, linestyle="--", alpha=0.7)
            else:
                l_vals = dist_plot["LSL"].dropna().unique()
                u_vals = dist_plot["USL"].dropna().unique()
                if l_vals.size:
                    ax2.axhline(l_vals[0], color="black", linestyle="--", alpha=0.7)
                if u_vals.size:
                    ax2.axhline(u_vals[0], color="black", linestyle="--", alpha=0.7)

        self.viz_canvas.draw()

    # ----------------- Failures and assessment -----------------
    def populate_failures(self):
        self.tree_fail.delete(*self.tree_fail.get_children())
        for f in self.failures:
            self.tree_fail.insert(
                "",
                "end",
                values=(f["Sheet"], f["SN"], f["Parameter"], f["Value"], f["LSL"], f["USL"], f["Type"]),
            )
        self.lbl_fail_summary.config(text=f"Total Failures Detected: {len(self.failures)}")

    def calculate_assessment(self):
        all_z = []
        for s, df in self.data_dict.items():
            cols = [c for c in df.columns if c != "SN"]
            num = df[cols].select_dtypes(include=[np.number])
            if "SN" in df.columns and not num.empty:
                num = num.copy()
                num.index = df["SN"].astype(str)
                z = (num - num.mean()) / num.std()
                all_z.append(z)

        if not all_z:
            return

        full_z = pd.concat(all_z, axis=1).fillna(0)
        abs_z = full_z.abs()
        scores = abs_z.sum(axis=1)
        max_z = abs_z.max(axis=1)
        cnt_z3 = (abs_z > 3).sum(axis=1)
        cnt_z6 = (abs_z > 6).sum(axis=1)

        rank_df = pd.DataFrame({
            "Score": scores,
            "MaxZ": max_z,
            "Count3": cnt_z3,
            "Count6": cnt_z6,
        }).sort_values("Score")

        best = rank_df.head(5).index.tolist()
        worst = rank_df.tail(5).index.tolist()[::-1]

        txt = "LOT ASSESSMENT REPORT\n" + "=" * 30 + "\n"
        txt += f"Best Performers (lowest overall |z|): {', '.join(map(str, best))}\n"
        txt += f"Worst Performers (highest overall |z|): {', '.join(map(str, worst))}\n"
        txt += "\nStrong outliers (Max |z| > 6):\n"
        strong = rank_df[rank_df["MaxZ"] > 6]
        if strong.empty:
            txt += "  None detected.\n"
        else:
            for sn, row in strong.sort_values("MaxZ", ascending=False).iterrows():
                txt += f"  SN {sn}: MaxZ={row['MaxZ']:.2f}, Count>|6|={int(row['Count6'])}\n"

        self.txt_assess.delete("1.0", tk.END)
        self.txt_assess.insert(tk.END, txt)

        self.tree_rank.delete(*self.tree_rank.get_children())
        rank_desc = rank_df.sort_values("Score", ascending=False)
        fail_counts = pd.DataFrame(self.failures)["SN"].value_counts() if self.failures else pd.Series(dtype=int)
        for i, (sn, row) in enumerate(rank_desc.iterrows(), start=1):
            self.tree_rank.insert(
                "",
                "end",
                values=(
                    i,
                    sn,
                    f"{row['Score']:.2f}",
                    f"{row['MaxZ']:.2f}",
                    int(row["Count3"]),
                    int(row["Count6"]),
                    fail_counts.get(sn, 0),
                ),
            )

    # ----------------- Report / export -----------------
    def generate_screen_report(self):
        for w in self.report_frame.winfo_children():
            w.destroy()

        ttk.Label(self.report_frame, text="Screen Report", font=("Arial", 14, "bold")).pack(anchor="w", pady=5)

        summary = tk.Text(self.report_frame, height=8, font=("Consolas", 10))
        summary.pack(fill=tk.X, padx=5, pady=5)

        total_sn = set()
        for df in self.data_dict.values():
            if "SN" in df.columns:
                total_sn.update(df["SN"].dropna().astype(str).tolist())

        summary.insert(
            tk.END,
            f"Total lots/devices (unique SN): {len(total_sn)}\n"
            f"Total failures: {len(self.failures)}\n"
            f"Total parameters with limits: {len(self.param_map)}\n",
        )

        cols = ("Parameter", "Count", "Mean", "Std", "Min", "Max")
        tree_stats = ttk.Treeview(self.report_frame, columns=cols, show="headings", height=15)
        for c in cols:
            tree_stats.heading(c, text=c)
            tree_stats.column(c, anchor="w", width=120)
        tree_stats.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        stats = {}
        for s, df in self.data_dict.items():
            for c in df.columns:
                if c == "SN":
                    continue
                base = self._get_base(c)
                vals = df[c].dropna()
                if vals.empty:
                    continue
                if base not in stats:
                    stats[base] = []
                stats[base].append(vals)

        for p, vlist in stats.items():
            allv = pd.concat(vlist)
            tree_stats.insert(
                "",
                "end",
                values=(
                    p,
                    int(allv.count()),
                    f"{allv.mean():.3f}",
                    f"{allv.std():.3f}",
                    f"{allv.min():.3f}",
                    f"{allv.max():.3f}",
                ),
            )

    def export_failures_csv(self):
        if not self.failures:
            messagebox.showinfo("Info", "No failures to export.")
            return
        path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV", "*.csv")])
        if not path:
            return
        pd.DataFrame(self.failures).to_csv(path, index=False)
        messagebox.showinfo("Export", f"Failures exported to {path}")

    def export_assessment_csv(self):
        if not self.data_dict:
            messagebox.showinfo("Info", "No data loaded.")
            return
        all_z = []
        for s, df in self.data_dict.items():
            cols = [c for c in df.columns if c != "SN"]
            num = df[cols].select_dtypes(include=[np.number])
            if "SN" in df.columns and not num.empty:
                num = num.copy()
                num.index = df["SN"].astype(str)
                z = (num - num.mean()) / num.std()
                all_z.append(z)
        if not all_z:
            messagebox.showinfo("Info", "No numeric data for assessment.")
            return
        full_z = pd.concat(all_z, axis=1).fillna(0)
        abs_z = full_z.abs()
        scores = abs_z.sum(axis=1)
        max_z = abs_z.max(axis=1)
        cnt_z3 = (abs_z > 3).sum(axis=1)
        cnt_z6 = (abs_z > 6).sum(axis=1)

        rank = pd.DataFrame({
            "SN": scores.index,
            "DeviationScore": scores.values,
            "MaxZ": max_z.values,
            "Count|Z|>3": cnt_z3.values,
            "Count|Z|>6": cnt_z6.values,
        }).sort_values("DeviationScore")

        path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV", "*.csv")])
        if not path:
            return
        rank.to_csv(path, index=False)
        messagebox.showinfo("Export", f"Assessment exported to {path}")

    # ----------------- Helpers -----------------
    def _process_headers(self, raw):
        clean = [str(h).strip() for h in raw if str(h).lower() != "nan"]
        if len(clean) > 5:
            b = len(clean) // 3
            if b > 0:
                s1, s2 = set(clean[:b]), set(clean[b : 2 * b])
                if b > 0 and len(s1 & s2) / b > 0.7:
                    self.is_tritemp = True
                    new_h = []
                    for i, h in enumerate(raw):
                        s = str(h).strip()
                        if i <= self.var_sn_col.get() + 1:
                            new_h.append(s)
                        else:
                            adj = i - (self.var_sn_col.get() + 2)
                            sub = max(1, (len(raw) - 2) // 3)
                            if adj < sub:
                                t = "(Room)"
                            elif adj < 2 * sub:
                                t = "(Cold)"
                            else:
                                t = "(Hot)"
                            new_h.append(f"{s} {t}")
                    return self._unique(new_h)
        return self._unique(raw)

    def _unique(self, headers):
        seen, out = {}, []
        for x in headers:
            s = str(x).strip()
            seen[s] = seen.get(s, -1) + 1
            out.append(f"{s}.{seen[s]}" if seen[s] > 0 else s)
        return out

    def _get_base(self, p):
        for t in ["(Room)", "(Cold)", "(Hot)"]:
            p = p.replace(t, "").strip()
        return p

    def _calc_cpk(self, v, l, u):
        if v.empty or v.std() == 0:
            return np.nan
        m, s = v.mean(), v.std()
        cpu = (u - m) / (3 * s) if not pd.isna(u) else np.nan
        cpl = (m - l) / (3 * s) if not pd.isna(l) else np.nan
        if pd.isna(cpu) and pd.isna(cpl):
            return np.nan
        if pd.isna(cpu):
            return cpl
        if pd.isna(cpl):
            return cpu
        return min(cpu, cpl)

    def _calc_robust_cpk(self, v, l, u):
        # 1. Safety Check: Not enough data
        if v.empty or len(v) < 5:
            return np.nan

        # 2. Check for Zero Variance (Constant data)
        # If the standard deviation is effectively 0, Cpk is technically infinite
        # (if within spec) or 0 (if out of spec). We return NaN to avoid plot errors.
        if v.std() < 1e-9:
            return np.nan

        # 3. Normality Test (Shapiro-Wilk)
        # If p > 0.05, we assume Normal distribution.
        stat, p_value = stats.shapiro(v)
        is_normal = p_value > 0.05

        cpu = np.inf
        cpl = np.inf

        if is_normal:
            # --- Parametric Calculation (Mean/Std) ---
            m, s = v.mean(), v.std()

            # Calculate Upper/Lower Cpk only if limits exist
            if not pd.isna(u):
                cpu = (u - m) / (3 * s)
            if not pd.isna(l):
                cpl = (m - l) / (3 * s)

        else:
            # --- Non-Parametric Calculation (Percentiles) ---
            median = v.median()
            # 99.865th percentile ~= +3 sigma
            p99_865 = np.percentile(v, 99.865)
            # 0.135th percentile ~= -3 sigma
            p0_135 = np.percentile(v, 0.135)

            # Safety: Prevent division by zero if percentiles equal median (flat data)
            upper_spread = max(1e-9, p99_865 - median)
            lower_spread = max(1e-9, median - p0_135)

            if not pd.isna(u):
                cpu = (u - median) / upper_spread
            if not pd.isna(l):
                cpl = (median - l) / lower_spread

        # 4. Final Result Handling
        result = min(cpu, cpl)

        # If both limits were NaN, result is still inf. Return NaN instead.
        if result == np.inf:
            return np.nan

        return result

    def _sort_cpk_tree(self, col, reverse):
        data = [(self.tree_cpk.set(k, col), k) for k in self.tree_cpk.get_children("")]
        if col in ("Cpk", "Mean"):
            data.sort(key=lambda t: float(t[0]), reverse=reverse)
        else:
            data.sort(key=lambda t: t[0], reverse=reverse)
        for idx, (_, k) in enumerate(data):
            self.tree_cpk.move(k, "", idx)
        self.tree_cpk.heading(col, command=lambda: self._sort_cpk_tree(col, not reverse))


if __name__ == "__main__":
    root = tk.Tk()
    app = QualAnalyzerV20(root)
    root.mainloop()
